{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import data_loader\n",
    "import numpy as np\n",
    "import sample_to_chords as s2c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "print('using',dev)\n",
    "device = torch.device(dev)\n",
    "class VAE(nn.Module):\n",
    "    N_CHORDS = 16\n",
    "    N_PITCH = 12\n",
    "    N_MAIN_QUALITY = 3\n",
    "    N_EXTRA_QUALITY = 3\n",
    "    \n",
    "    SIZE_HIDDEN = 400\n",
    "    SIZE_LATENT = 40\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.N_CHORDS * (self.N_PITCH * self.N_MAIN_QUALITY + self.N_EXTRA_QUALITY), self.SIZE_HIDDEN)\n",
    "        self.fc21 = nn.Linear(self.SIZE_HIDDEN, self.SIZE_LATENT)\n",
    "        self.fc22 = nn.Linear(self.SIZE_HIDDEN, self.SIZE_LATENT)\n",
    "        \n",
    "        self.fc3 = nn.Linear(self.SIZE_LATENT, self.SIZE_HIDDEN)\n",
    "        self.fc4 = nn.Linear(self.SIZE_HIDDEN, self.N_CHORDS * (self.N_PITCH * self.N_MAIN_QUALITY + self.N_EXTRA_QUALITY))\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        soft = nn.Sigmoid()\n",
    "        return soft(self.fc4(h3).view(-1, self.N_CHORDS, self.N_PITCH * self.N_MAIN_QUALITY + self.N_EXTRA_QUALITY))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.N_CHORDS * (self.N_PITCH * self.N_MAIN_QUALITY + self.N_EXTRA_QUALITY)))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar, beta):\n",
    "    BCE = F.binary_cross_entropy(recon_x.view(-1, 16*(12*3 + 3)), x.view(-1, 16*(12*3 + 3)), reduction='sum')\n",
    "\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + beta*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    beta = epoch/epochs\n",
    "    for batch_idx, data in enumerate(realbook_dataset):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar, beta)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), Nchunks,\n",
    "                100. * batch_idx * len(data)/ Nchunks,\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / Nchunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded !\n"
     ]
    }
   ],
   "source": [
    "realbook_dataset = data_loader.import_dataset()\n",
    "Nchunks = len(realbook_dataset)\n",
    "realbook_dataset = torch.split(realbook_dataset, batch_size, 0)\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model_realbook.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/391165 (0%)]\tLoss: 436.362000\n",
      "Train Epoch: 1 [12800/391165 (3%)]\tLoss: 105.533058\n",
      "Train Epoch: 1 [25600/391165 (7%)]\tLoss: 41.849136\n",
      "Train Epoch: 1 [38400/391165 (10%)]\tLoss: 60.875565\n",
      "Train Epoch: 1 [51200/391165 (13%)]\tLoss: 46.579243\n",
      "Train Epoch: 1 [64000/391165 (16%)]\tLoss: 60.211094\n",
      "Train Epoch: 1 [76800/391165 (20%)]\tLoss: 67.063644\n",
      "Train Epoch: 1 [89600/391165 (23%)]\tLoss: 59.873924\n",
      "Train Epoch: 1 [102400/391165 (26%)]\tLoss: 30.193012\n",
      "Train Epoch: 1 [115200/391165 (29%)]\tLoss: 29.191622\n",
      "Train Epoch: 1 [128000/391165 (33%)]\tLoss: 44.134834\n",
      "Train Epoch: 1 [140800/391165 (36%)]\tLoss: 30.002827\n",
      "Train Epoch: 1 [153600/391165 (39%)]\tLoss: 30.823315\n",
      "Train Epoch: 1 [166400/391165 (43%)]\tLoss: 30.754322\n",
      "Train Epoch: 1 [179200/391165 (46%)]\tLoss: 37.077034\n",
      "Train Epoch: 1 [192000/391165 (49%)]\tLoss: 28.699638\n",
      "Train Epoch: 1 [204800/391165 (52%)]\tLoss: 42.965057\n",
      "Train Epoch: 1 [217600/391165 (56%)]\tLoss: 16.419180\n",
      "Train Epoch: 1 [230400/391165 (59%)]\tLoss: 33.554047\n",
      "Train Epoch: 1 [243200/391165 (62%)]\tLoss: 12.225382\n",
      "Train Epoch: 1 [256000/391165 (65%)]\tLoss: 33.142941\n",
      "Train Epoch: 1 [268800/391165 (69%)]\tLoss: 17.731026\n",
      "Train Epoch: 1 [281600/391165 (72%)]\tLoss: 27.840332\n",
      "Train Epoch: 1 [294400/391165 (75%)]\tLoss: 25.609068\n",
      "Train Epoch: 1 [307200/391165 (79%)]\tLoss: 21.693665\n",
      "Train Epoch: 1 [320000/391165 (82%)]\tLoss: 23.494698\n",
      "Train Epoch: 1 [332800/391165 (85%)]\tLoss: 14.518009\n",
      "Train Epoch: 1 [345600/391165 (88%)]\tLoss: 19.670349\n",
      "Train Epoch: 1 [358400/391165 (92%)]\tLoss: 13.824045\n",
      "Train Epoch: 1 [371200/391165 (95%)]\tLoss: 44.613972\n",
      "Train Epoch: 1 [384000/391165 (98%)]\tLoss: 21.970198\n",
      "====> Epoch: 1 Average loss: 38.4286\n",
      "Train Epoch: 2 [0/391165 (0%)]\tLoss: 22.742134\n",
      "Train Epoch: 2 [12800/391165 (3%)]\tLoss: 25.553993\n",
      "Train Epoch: 2 [25600/391165 (7%)]\tLoss: 11.586081\n",
      "Train Epoch: 2 [38400/391165 (10%)]\tLoss: 18.692368\n",
      "Train Epoch: 2 [51200/391165 (13%)]\tLoss: 18.182697\n",
      "Train Epoch: 2 [64000/391165 (16%)]\tLoss: 17.428722\n",
      "Train Epoch: 2 [76800/391165 (20%)]\tLoss: 30.737591\n",
      "Train Epoch: 2 [89600/391165 (23%)]\tLoss: 33.104328\n",
      "Train Epoch: 2 [102400/391165 (26%)]\tLoss: 19.137651\n",
      "Train Epoch: 2 [115200/391165 (29%)]\tLoss: 16.519287\n",
      "Train Epoch: 2 [128000/391165 (33%)]\tLoss: 26.645325\n",
      "Train Epoch: 2 [140800/391165 (36%)]\tLoss: 18.425175\n",
      "Train Epoch: 2 [153600/391165 (39%)]\tLoss: 18.723331\n",
      "Train Epoch: 2 [166400/391165 (43%)]\tLoss: 25.590660\n",
      "Train Epoch: 2 [179200/391165 (46%)]\tLoss: 24.447823\n",
      "Train Epoch: 2 [192000/391165 (49%)]\tLoss: 19.291821\n",
      "Train Epoch: 2 [204800/391165 (52%)]\tLoss: 32.783443\n",
      "Train Epoch: 2 [217600/391165 (56%)]\tLoss: 13.619809\n",
      "Train Epoch: 2 [230400/391165 (59%)]\tLoss: 30.464577\n",
      "Train Epoch: 2 [243200/391165 (62%)]\tLoss: 11.103958\n",
      "Train Epoch: 2 [256000/391165 (65%)]\tLoss: 28.755348\n",
      "Train Epoch: 2 [268800/391165 (69%)]\tLoss: 17.788961\n",
      "Train Epoch: 2 [281600/391165 (72%)]\tLoss: 22.014919\n",
      "Train Epoch: 2 [294400/391165 (75%)]\tLoss: 24.502850\n",
      "Train Epoch: 2 [307200/391165 (79%)]\tLoss: 19.565372\n",
      "Train Epoch: 2 [320000/391165 (82%)]\tLoss: 21.079647\n",
      "Train Epoch: 2 [332800/391165 (85%)]\tLoss: 13.997671\n",
      "Train Epoch: 2 [345600/391165 (88%)]\tLoss: 18.140919\n",
      "Train Epoch: 2 [358400/391165 (92%)]\tLoss: 13.812263\n",
      "Train Epoch: 2 [371200/391165 (95%)]\tLoss: 41.396378\n",
      "Train Epoch: 2 [384000/391165 (98%)]\tLoss: 22.425106\n",
      "====> Epoch: 2 Average loss: 22.4146\n",
      "Train Epoch: 3 [0/391165 (0%)]\tLoss: 21.870893\n",
      "Train Epoch: 3 [12800/391165 (3%)]\tLoss: 25.142401\n",
      "Train Epoch: 3 [25600/391165 (7%)]\tLoss: 12.621841\n",
      "Train Epoch: 3 [38400/391165 (10%)]\tLoss: 18.903011\n",
      "Train Epoch: 3 [51200/391165 (13%)]\tLoss: 18.606937\n",
      "Train Epoch: 3 [64000/391165 (16%)]\tLoss: 18.174709\n",
      "Train Epoch: 3 [76800/391165 (20%)]\tLoss: 29.415302\n",
      "Train Epoch: 3 [89600/391165 (23%)]\tLoss: 31.889462\n",
      "Train Epoch: 3 [102400/391165 (26%)]\tLoss: 19.548822\n",
      "Train Epoch: 3 [115200/391165 (29%)]\tLoss: 17.799503\n",
      "Train Epoch: 3 [128000/391165 (33%)]\tLoss: 25.471249\n",
      "Train Epoch: 3 [140800/391165 (36%)]\tLoss: 18.773880\n",
      "Train Epoch: 3 [153600/391165 (39%)]\tLoss: 18.913637\n",
      "Train Epoch: 3 [166400/391165 (43%)]\tLoss: 27.308136\n",
      "Train Epoch: 3 [179200/391165 (46%)]\tLoss: 25.061359\n",
      "Train Epoch: 3 [192000/391165 (49%)]\tLoss: 21.054348\n",
      "Train Epoch: 3 [204800/391165 (52%)]\tLoss: 33.401329\n",
      "Train Epoch: 3 [217600/391165 (56%)]\tLoss: 15.704972\n",
      "Train Epoch: 3 [230400/391165 (59%)]\tLoss: 29.993622\n",
      "Train Epoch: 3 [243200/391165 (62%)]\tLoss: 13.444855\n",
      "Train Epoch: 3 [256000/391165 (65%)]\tLoss: 30.487556\n",
      "Train Epoch: 3 [268800/391165 (69%)]\tLoss: 19.867609\n",
      "Train Epoch: 3 [281600/391165 (72%)]\tLoss: 23.752935\n",
      "Train Epoch: 3 [294400/391165 (75%)]\tLoss: 26.675613\n",
      "Train Epoch: 3 [307200/391165 (79%)]\tLoss: 22.365944\n",
      "Train Epoch: 3 [320000/391165 (82%)]\tLoss: 23.009754\n",
      "Train Epoch: 3 [332800/391165 (85%)]\tLoss: 15.242692\n",
      "Train Epoch: 3 [345600/391165 (88%)]\tLoss: 21.199688\n",
      "Train Epoch: 3 [358400/391165 (92%)]\tLoss: 16.893215\n",
      "Train Epoch: 3 [371200/391165 (95%)]\tLoss: 43.527809\n",
      "Train Epoch: 3 [384000/391165 (98%)]\tLoss: 24.568352\n",
      "====> Epoch: 3 Average loss: 23.4053\n",
      "Train Epoch: 4 [0/391165 (0%)]\tLoss: 23.889812\n",
      "Train Epoch: 4 [12800/391165 (3%)]\tLoss: 28.075169\n",
      "Train Epoch: 4 [25600/391165 (7%)]\tLoss: 13.750364\n",
      "Train Epoch: 4 [38400/391165 (10%)]\tLoss: 21.106823\n",
      "Train Epoch: 4 [51200/391165 (13%)]\tLoss: 20.824879\n",
      "Train Epoch: 4 [64000/391165 (16%)]\tLoss: 21.008307\n",
      "Train Epoch: 4 [76800/391165 (20%)]\tLoss: 31.956547\n",
      "Train Epoch: 4 [89600/391165 (23%)]\tLoss: 34.494850\n",
      "Train Epoch: 4 [102400/391165 (26%)]\tLoss: 21.601080\n",
      "Train Epoch: 4 [115200/391165 (29%)]\tLoss: 19.696812\n",
      "Train Epoch: 4 [128000/391165 (33%)]\tLoss: 28.190002\n",
      "Train Epoch: 4 [140800/391165 (36%)]\tLoss: 21.575134\n",
      "Train Epoch: 4 [153600/391165 (39%)]\tLoss: 22.716553\n",
      "Train Epoch: 4 [166400/391165 (43%)]\tLoss: 29.353161\n",
      "Train Epoch: 4 [179200/391165 (46%)]\tLoss: 27.887344\n",
      "Train Epoch: 4 [192000/391165 (49%)]\tLoss: 23.346727\n",
      "Train Epoch: 4 [204800/391165 (52%)]\tLoss: 36.126137\n",
      "Train Epoch: 4 [217600/391165 (56%)]\tLoss: 17.828140\n",
      "Train Epoch: 4 [230400/391165 (59%)]\tLoss: 32.408020\n",
      "Train Epoch: 4 [243200/391165 (62%)]\tLoss: 15.667673\n",
      "Train Epoch: 4 [256000/391165 (65%)]\tLoss: 33.168606\n",
      "Train Epoch: 4 [268800/391165 (69%)]\tLoss: 22.137928\n",
      "Train Epoch: 4 [281600/391165 (72%)]\tLoss: 27.054962\n",
      "Train Epoch: 4 [294400/391165 (75%)]\tLoss: 28.330637\n",
      "Train Epoch: 4 [307200/391165 (79%)]\tLoss: 25.036381\n",
      "Train Epoch: 4 [320000/391165 (82%)]\tLoss: 26.118820\n",
      "Train Epoch: 4 [332800/391165 (85%)]\tLoss: 17.833181\n",
      "Train Epoch: 4 [345600/391165 (88%)]\tLoss: 24.506424\n",
      "Train Epoch: 4 [358400/391165 (92%)]\tLoss: 19.418129\n",
      "Train Epoch: 4 [371200/391165 (95%)]\tLoss: 47.407619\n",
      "Train Epoch: 4 [384000/391165 (98%)]\tLoss: 27.250488\n",
      "====> Epoch: 4 Average loss: 25.9134\n",
      "Train Epoch: 5 [0/391165 (0%)]\tLoss: 26.123960\n",
      "Train Epoch: 5 [12800/391165 (3%)]\tLoss: 30.084377\n",
      "Train Epoch: 5 [25600/391165 (7%)]\tLoss: 15.033622\n",
      "Train Epoch: 5 [38400/391165 (10%)]\tLoss: 23.681931\n",
      "Train Epoch: 5 [51200/391165 (13%)]\tLoss: 23.216543\n",
      "Train Epoch: 5 [64000/391165 (16%)]\tLoss: 22.858238\n",
      "Train Epoch: 5 [76800/391165 (20%)]\tLoss: 34.568996\n",
      "Train Epoch: 5 [89600/391165 (23%)]\tLoss: 36.857075\n",
      "Train Epoch: 5 [102400/391165 (26%)]\tLoss: 23.748135\n",
      "Train Epoch: 5 [115200/391165 (29%)]\tLoss: 22.279686\n",
      "Train Epoch: 5 [128000/391165 (33%)]\tLoss: 31.732555\n",
      "Train Epoch: 5 [140800/391165 (36%)]\tLoss: 24.161760\n",
      "Train Epoch: 5 [153600/391165 (39%)]\tLoss: 24.920765\n",
      "Train Epoch: 5 [166400/391165 (43%)]\tLoss: 31.132784\n",
      "Train Epoch: 5 [179200/391165 (46%)]\tLoss: 31.194033\n",
      "Train Epoch: 5 [192000/391165 (49%)]\tLoss: 26.131207\n",
      "Train Epoch: 5 [204800/391165 (52%)]\tLoss: 39.182766\n",
      "Train Epoch: 5 [217600/391165 (56%)]\tLoss: 20.607546\n",
      "Train Epoch: 5 [230400/391165 (59%)]\tLoss: 34.329086\n",
      "Train Epoch: 5 [243200/391165 (62%)]\tLoss: 18.050961\n",
      "Train Epoch: 5 [256000/391165 (65%)]\tLoss: 36.398521\n",
      "Train Epoch: 5 [268800/391165 (69%)]\tLoss: 25.627613\n",
      "Train Epoch: 5 [281600/391165 (72%)]\tLoss: 30.509022\n",
      "Train Epoch: 5 [294400/391165 (75%)]\tLoss: 31.895052\n",
      "Train Epoch: 5 [307200/391165 (79%)]\tLoss: 28.380552\n",
      "Train Epoch: 5 [320000/391165 (82%)]\tLoss: 29.515818\n",
      "Train Epoch: 5 [332800/391165 (85%)]\tLoss: 20.397993\n",
      "Train Epoch: 5 [345600/391165 (88%)]\tLoss: 27.642231\n",
      "Train Epoch: 5 [358400/391165 (92%)]\tLoss: 21.649992\n",
      "Train Epoch: 5 [371200/391165 (95%)]\tLoss: 50.342148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [384000/391165 (98%)]\tLoss: 30.977482\n",
      "====> Epoch: 5 Average loss: 28.5836\n",
      "Train Epoch: 6 [0/391165 (0%)]\tLoss: 29.092850\n",
      "Train Epoch: 6 [12800/391165 (3%)]\tLoss: 33.543308\n",
      "Train Epoch: 6 [25600/391165 (7%)]\tLoss: 16.286705\n",
      "Train Epoch: 6 [38400/391165 (10%)]\tLoss: 25.827057\n",
      "Train Epoch: 6 [51200/391165 (13%)]\tLoss: 25.507492\n",
      "Train Epoch: 6 [64000/391165 (16%)]\tLoss: 26.236574\n",
      "Train Epoch: 6 [76800/391165 (20%)]\tLoss: 37.843002\n",
      "Train Epoch: 6 [89600/391165 (23%)]\tLoss: 40.653912\n",
      "Train Epoch: 6 [102400/391165 (26%)]\tLoss: 26.135548\n",
      "Train Epoch: 6 [115200/391165 (29%)]\tLoss: 24.529434\n",
      "Train Epoch: 6 [128000/391165 (33%)]\tLoss: 33.843670\n",
      "Train Epoch: 6 [140800/391165 (36%)]\tLoss: 27.125412\n",
      "Train Epoch: 6 [153600/391165 (39%)]\tLoss: 28.127317\n",
      "Train Epoch: 6 [166400/391165 (43%)]\tLoss: 34.166199\n",
      "Train Epoch: 6 [179200/391165 (46%)]\tLoss: 34.394867\n",
      "Train Epoch: 6 [192000/391165 (49%)]\tLoss: 28.952433\n",
      "Train Epoch: 6 [204800/391165 (52%)]\tLoss: 40.766735\n",
      "Train Epoch: 6 [217600/391165 (56%)]\tLoss: 22.887012\n",
      "Train Epoch: 6 [230400/391165 (59%)]\tLoss: 38.204830\n",
      "Train Epoch: 6 [243200/391165 (62%)]\tLoss: 19.482746\n",
      "Train Epoch: 6 [256000/391165 (65%)]\tLoss: 38.961105\n",
      "Train Epoch: 6 [268800/391165 (69%)]\tLoss: 27.833961\n",
      "Train Epoch: 6 [281600/391165 (72%)]\tLoss: 34.193848\n",
      "Train Epoch: 6 [294400/391165 (75%)]\tLoss: 33.362728\n",
      "Train Epoch: 6 [307200/391165 (79%)]\tLoss: 31.328827\n",
      "Train Epoch: 6 [320000/391165 (82%)]\tLoss: 32.433037\n",
      "Train Epoch: 6 [332800/391165 (85%)]\tLoss: 23.162210\n",
      "Train Epoch: 6 [345600/391165 (88%)]\tLoss: 29.607672\n",
      "Train Epoch: 6 [358400/391165 (92%)]\tLoss: 24.498947\n",
      "Train Epoch: 6 [371200/391165 (95%)]\tLoss: 53.636436\n",
      "Train Epoch: 6 [384000/391165 (98%)]\tLoss: 33.715424\n",
      "====> Epoch: 6 Average loss: 31.2386\n",
      "Train Epoch: 7 [0/391165 (0%)]\tLoss: 30.737041\n",
      "Train Epoch: 7 [12800/391165 (3%)]\tLoss: 33.799408\n",
      "Train Epoch: 7 [25600/391165 (7%)]\tLoss: 18.737118\n",
      "Train Epoch: 7 [38400/391165 (10%)]\tLoss: 29.173817\n",
      "Train Epoch: 7 [51200/391165 (13%)]\tLoss: 27.566364\n",
      "Train Epoch: 7 [64000/391165 (16%)]\tLoss: 28.377668\n",
      "Train Epoch: 7 [76800/391165 (20%)]\tLoss: 41.348648\n",
      "Train Epoch: 7 [89600/391165 (23%)]\tLoss: 43.973022\n",
      "Train Epoch: 7 [102400/391165 (26%)]\tLoss: 27.224754\n",
      "Train Epoch: 7 [115200/391165 (29%)]\tLoss: 26.762650\n",
      "Train Epoch: 7 [128000/391165 (33%)]\tLoss: 35.869602\n",
      "Train Epoch: 7 [140800/391165 (36%)]\tLoss: 29.408897\n",
      "Train Epoch: 7 [153600/391165 (39%)]\tLoss: 31.449417\n",
      "Train Epoch: 7 [166400/391165 (43%)]\tLoss: 36.558952\n",
      "Train Epoch: 7 [179200/391165 (46%)]\tLoss: 38.193008\n",
      "Train Epoch: 7 [192000/391165 (49%)]\tLoss: 31.885130\n",
      "Train Epoch: 7 [204800/391165 (52%)]\tLoss: 44.618500\n",
      "Train Epoch: 7 [217600/391165 (56%)]\tLoss: 25.294403\n",
      "Train Epoch: 7 [230400/391165 (59%)]\tLoss: 39.306328\n",
      "Train Epoch: 7 [243200/391165 (62%)]\tLoss: 22.063690\n",
      "Train Epoch: 7 [256000/391165 (65%)]\tLoss: 42.115234\n",
      "Train Epoch: 7 [268800/391165 (69%)]\tLoss: 30.481623\n",
      "Train Epoch: 7 [281600/391165 (72%)]\tLoss: 35.711319\n",
      "Train Epoch: 7 [294400/391165 (75%)]\tLoss: 36.528183\n",
      "Train Epoch: 7 [307200/391165 (79%)]\tLoss: 34.296928\n",
      "Train Epoch: 7 [320000/391165 (82%)]\tLoss: 35.192360\n",
      "Train Epoch: 7 [332800/391165 (85%)]\tLoss: 26.391693\n",
      "Train Epoch: 7 [345600/391165 (88%)]\tLoss: 32.825005\n",
      "Train Epoch: 7 [358400/391165 (92%)]\tLoss: 25.921280\n",
      "Train Epoch: 7 [371200/391165 (95%)]\tLoss: 57.367912\n",
      "Train Epoch: 7 [384000/391165 (98%)]\tLoss: 35.758739\n",
      "====> Epoch: 7 Average loss: 33.7572\n",
      "Train Epoch: 8 [0/391165 (0%)]\tLoss: 33.667480\n",
      "Train Epoch: 8 [12800/391165 (3%)]\tLoss: 37.111546\n",
      "Train Epoch: 8 [25600/391165 (7%)]\tLoss: 19.393101\n",
      "Train Epoch: 8 [38400/391165 (10%)]\tLoss: 30.573597\n",
      "Train Epoch: 8 [51200/391165 (13%)]\tLoss: 29.827751\n",
      "Train Epoch: 8 [64000/391165 (16%)]\tLoss: 29.864601\n",
      "Train Epoch: 8 [76800/391165 (20%)]\tLoss: 43.104759\n",
      "Train Epoch: 8 [89600/391165 (23%)]\tLoss: 46.900955\n",
      "Train Epoch: 8 [102400/391165 (26%)]\tLoss: 30.173300\n",
      "Train Epoch: 8 [115200/391165 (29%)]\tLoss: 29.655439\n",
      "Train Epoch: 8 [128000/391165 (33%)]\tLoss: 39.805923\n",
      "Train Epoch: 8 [140800/391165 (36%)]\tLoss: 31.628746\n",
      "Train Epoch: 8 [153600/391165 (39%)]\tLoss: 33.727413\n",
      "Train Epoch: 8 [166400/391165 (43%)]\tLoss: 38.988098\n",
      "Train Epoch: 8 [179200/391165 (46%)]\tLoss: 41.251503\n",
      "Train Epoch: 8 [192000/391165 (49%)]\tLoss: 34.364246\n",
      "Train Epoch: 8 [204800/391165 (52%)]\tLoss: 47.690277\n",
      "Train Epoch: 8 [217600/391165 (56%)]\tLoss: 26.735701\n",
      "Train Epoch: 8 [230400/391165 (59%)]\tLoss: 42.471519\n",
      "Train Epoch: 8 [243200/391165 (62%)]\tLoss: 24.078585\n",
      "Train Epoch: 8 [256000/391165 (65%)]\tLoss: 43.833286\n",
      "Train Epoch: 8 [268800/391165 (69%)]\tLoss: 32.768703\n",
      "Train Epoch: 8 [281600/391165 (72%)]\tLoss: 38.613304\n",
      "Train Epoch: 8 [294400/391165 (75%)]\tLoss: 37.668694\n",
      "Train Epoch: 8 [307200/391165 (79%)]\tLoss: 36.752274\n",
      "Train Epoch: 8 [320000/391165 (82%)]\tLoss: 37.402737\n",
      "Train Epoch: 8 [332800/391165 (85%)]\tLoss: 28.290915\n",
      "Train Epoch: 8 [345600/391165 (88%)]\tLoss: 36.308281\n",
      "Train Epoch: 8 [358400/391165 (92%)]\tLoss: 28.467611\n",
      "Train Epoch: 8 [371200/391165 (95%)]\tLoss: 60.318459\n",
      "Train Epoch: 8 [384000/391165 (98%)]\tLoss: 39.035934\n",
      "====> Epoch: 8 Average loss: 36.1858\n",
      "Train Epoch: 9 [0/391165 (0%)]\tLoss: 36.429028\n",
      "Train Epoch: 9 [12800/391165 (3%)]\tLoss: 39.143379\n",
      "Train Epoch: 9 [25600/391165 (7%)]\tLoss: 20.582693\n",
      "Train Epoch: 9 [38400/391165 (10%)]\tLoss: 32.937027\n",
      "Train Epoch: 9 [51200/391165 (13%)]\tLoss: 31.605927\n",
      "Train Epoch: 9 [64000/391165 (16%)]\tLoss: 31.197924\n",
      "Train Epoch: 9 [76800/391165 (20%)]\tLoss: 46.846672\n",
      "Train Epoch: 9 [89600/391165 (23%)]\tLoss: 49.752846\n",
      "Train Epoch: 9 [102400/391165 (26%)]\tLoss: 31.377460\n",
      "Train Epoch: 9 [115200/391165 (29%)]\tLoss: 31.523830\n",
      "Train Epoch: 9 [128000/391165 (33%)]\tLoss: 41.410851\n",
      "Train Epoch: 9 [140800/391165 (36%)]\tLoss: 34.121605\n",
      "Train Epoch: 9 [153600/391165 (39%)]\tLoss: 36.432434\n",
      "Train Epoch: 9 [166400/391165 (43%)]\tLoss: 40.533047\n",
      "Train Epoch: 9 [179200/391165 (46%)]\tLoss: 43.769890\n",
      "Train Epoch: 9 [192000/391165 (49%)]\tLoss: 35.580200\n",
      "Train Epoch: 9 [204800/391165 (52%)]\tLoss: 50.491493\n",
      "Train Epoch: 9 [217600/391165 (56%)]\tLoss: 28.444683\n",
      "Train Epoch: 9 [230400/391165 (59%)]\tLoss: 44.219650\n",
      "Train Epoch: 9 [243200/391165 (62%)]\tLoss: 25.881838\n",
      "Train Epoch: 9 [256000/391165 (65%)]\tLoss: 46.456841\n",
      "Train Epoch: 9 [268800/391165 (69%)]\tLoss: 35.809887\n",
      "Train Epoch: 9 [281600/391165 (72%)]\tLoss: 42.136955\n",
      "Train Epoch: 9 [294400/391165 (75%)]\tLoss: 39.820889\n",
      "Train Epoch: 9 [307200/391165 (79%)]\tLoss: 38.778069\n",
      "Train Epoch: 9 [320000/391165 (82%)]\tLoss: 41.233604\n",
      "Train Epoch: 9 [332800/391165 (85%)]\tLoss: 30.141060\n",
      "Train Epoch: 9 [345600/391165 (88%)]\tLoss: 37.193737\n",
      "Train Epoch: 9 [358400/391165 (92%)]\tLoss: 30.440815\n",
      "Train Epoch: 9 [371200/391165 (95%)]\tLoss: 63.444057\n",
      "Train Epoch: 9 [384000/391165 (98%)]\tLoss: 41.120518\n",
      "====> Epoch: 9 Average loss: 38.4631\n",
      "Train Epoch: 10 [0/391165 (0%)]\tLoss: 38.503185\n",
      "Train Epoch: 10 [12800/391165 (3%)]\tLoss: 41.110245\n",
      "Train Epoch: 10 [25600/391165 (7%)]\tLoss: 21.977310\n",
      "Train Epoch: 10 [38400/391165 (10%)]\tLoss: 34.963341\n",
      "Train Epoch: 10 [51200/391165 (13%)]\tLoss: 33.502804\n",
      "Train Epoch: 10 [64000/391165 (16%)]\tLoss: 33.378502\n",
      "Train Epoch: 10 [76800/391165 (20%)]\tLoss: 48.618874\n",
      "Train Epoch: 10 [89600/391165 (23%)]\tLoss: 52.476814\n",
      "Train Epoch: 10 [102400/391165 (26%)]\tLoss: 34.259548\n",
      "Train Epoch: 10 [115200/391165 (29%)]\tLoss: 33.272858\n",
      "Train Epoch: 10 [128000/391165 (33%)]\tLoss: 44.197567\n",
      "Train Epoch: 10 [140800/391165 (36%)]\tLoss: 36.478149\n",
      "Train Epoch: 10 [153600/391165 (39%)]\tLoss: 39.768433\n",
      "Train Epoch: 10 [166400/391165 (43%)]\tLoss: 42.359398\n",
      "Train Epoch: 10 [179200/391165 (46%)]\tLoss: 46.916794\n",
      "Train Epoch: 10 [192000/391165 (49%)]\tLoss: 38.473152\n",
      "Train Epoch: 10 [204800/391165 (52%)]\tLoss: 53.227459\n",
      "Train Epoch: 10 [217600/391165 (56%)]\tLoss: 29.703733\n",
      "Train Epoch: 10 [230400/391165 (59%)]\tLoss: 46.326767\n",
      "Train Epoch: 10 [243200/391165 (62%)]\tLoss: 26.358727\n",
      "Train Epoch: 10 [256000/391165 (65%)]\tLoss: 48.511368\n",
      "Train Epoch: 10 [268800/391165 (69%)]\tLoss: 37.066139\n",
      "Train Epoch: 10 [281600/391165 (72%)]\tLoss: 44.638664\n",
      "Train Epoch: 10 [294400/391165 (75%)]\tLoss: 42.520058\n",
      "Train Epoch: 10 [307200/391165 (79%)]\tLoss: 41.396843\n",
      "Train Epoch: 10 [320000/391165 (82%)]\tLoss: 42.425953\n",
      "Train Epoch: 10 [332800/391165 (85%)]\tLoss: 33.014412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [345600/391165 (88%)]\tLoss: 39.798931\n",
      "Train Epoch: 10 [358400/391165 (92%)]\tLoss: 31.765024\n",
      "Train Epoch: 10 [371200/391165 (95%)]\tLoss: 66.449364\n",
      "Train Epoch: 10 [384000/391165 (98%)]\tLoss: 43.070679\n",
      "====> Epoch: 10 Average loss: 40.6060\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_realbook.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérité\n",
      "torch.Size([16, 39])\n",
      "['A:min:min7', 'A:min:min7', 'A:min:min7', 'A:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'F:maj:maj7', 'F:maj:maj7', 'F:maj:maj7', 'F:maj:maj7']\n",
      "\n",
      "Par VAE\n",
      "['A:min:min7', 'A:min:min7', 'A:min:min7', 'A:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'E:min:min7', 'A:maj:min7', 'F:maj:min7', 'F:maj:min7', 'F:maj:maj7', 'F:maj:maj7']\n"
     ]
    }
   ],
   "source": [
    "index_test = 68\n",
    "test_sample = realbook_dataset[0][index_test]\n",
    "\n",
    "print(\"Vérité\")\n",
    "print(test_sample.shape)\n",
    "print(data_loader.tensor_to_chunk(test_sample))\n",
    "\n",
    "print()\n",
    "print(\"Par VAE\")\n",
    "model.to(torch.device(\"cpu\"))\n",
    "recons_test, _, _ = model(test_sample)\n",
    "print(data_loader.tensor_to_chunk(recons_test.detach()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 39])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A:min:N',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'A:min:min7',\n",
       " 'D:min:min7',\n",
       " 'B:maj:min7',\n",
       " 'G:min:min7',\n",
       " 'C:maj:min7',\n",
       " 'C:maj:N',\n",
       " 'C:maj:N',\n",
       " 'C:maj:N']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_LATENT = 40\n",
    "with torch.no_grad():\n",
    "    sample = torch.randn(1, N_LATENT)\n",
    "    sample = model.decode(sample).cpu()\n",
    "    sample = sample.detach()[0]\n",
    "print(sample.shape)\n",
    "data_loader.tensor_to_chunk(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
